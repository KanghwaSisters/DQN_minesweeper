{"cells":[{"cell_type":"markdown","metadata":{"id":"rdETq6egdSWb"},"source":["# 00 Init"]},{"cell_type":"markdown","metadata":{"id":"8HOAjQuwL7sN"},"source":["## Mount"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16694,"status":"ok","timestamp":1716019956458,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"},"user_tz":-540},"id":"ui3DIJhjL9gg","outputId":"629388e1-7b50-417f-d74b-c18518de84a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"78w_wKa0U7RQ"},"source":["## Setting to use py files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pxUvG0xL7sP"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMOGX54HPnN4"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/Minesweeper [RL]')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716019956459,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"},"user_tz":-540},"id":"Irw-aDyCMS39","outputId":"91834c5a-26a3-493f-95cd-eb0944594837"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Minesweeper [RL]'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# check that os is in right directory\n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7169,"status":"ok","timestamp":1716019963623,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"},"user_tz":-540},"id":"Sr1xfdJ6PsFk","outputId":"5b3cce16-fc4e-4f52-f07c-6c69763a0ec9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting codes\n","  Downloading codes-0.1.5-py3-none-any.whl (5.5 kB)\n","Installing collected packages: codes\n","Successfully installed codes-0.1.5\n"]}],"source":["! pip install codes"]},{"cell_type":"markdown","metadata":{"id":"tOZz1bXTVUae"},"source":["## Import py files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QtWl0d3Owjd"},"outputs":[],"source":["# baseline : Env, Agent\n","# from codes.environment.reward5 import *\n","from codes.environment.reward5 import *\n","from codes.agent.scalarDQN import *\n","from codes.net.basicWithBias import *\n","from codes.trainer.validShutDown import *\n","from codes.tester.validShutDown import *\n","# import codes.trainer.trainerWithValidShutDown as Trainer\n"]},{"cell_type":"markdown","metadata":{"id":"EQB8jukRfMvE"},"source":["## Import Libraries"]},{"cell_type":"markdown","metadata":{"id":"pmz1e_BTfYrZ"},"source":["# 01 Info"]},{"cell_type":"markdown","metadata":{"id":"1p29QQ5GAndP"},"source":["## level dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vso5fXO-_hH8"},"outputs":[],"source":["level = {'easy' : {'map_size':(9,9), 'n_mines' : 10},\n","         'medium' : {'map_size':(16,16), 'n_mines':40},\n","         'expert' : {'map_size':(16,30), 'n_mines':99}}"]},{"cell_type":"markdown","metadata":{"id":"M9gDUMM9WBXa"},"source":["## HYPER PARAMETERS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ru8shHIbWDZX"},"outputs":[],"source":["# Environment settings\n","MEM_SIZE = 200000\n","MEM_SIZE_MIN = 1000\n","\n","# Learning settings\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","LEARN_DECAY = 0.9999975\n","LEARN_MIN = 0.0001 # 0.001\n","DISCOUNT = 0.1\n","\n","# Exploration settings\n","EPSILON = 0.95\n","EPSILON_DECAY = 0.999975\n","EPSILON_MIN = 0.01\n","\n","# DQN settings\n","CONV_UNITS = 64\n","UPDATE_TARGET_EVERY = 5"]},{"cell_type":"markdown","metadata":{"id":"dv56uz9IIexK"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":179590,"status":"error","timestamp":1716020155419,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"},"user_tz":-540},"id":"BVk9tzXRIhhM","outputId":"e44b40ca-bcad-4100-82be-78ec0098c6cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: [50000/100], Median progress: 6.00, Median reward: -0.70, Win rate : 0.23, Epsilon: 0.95\n","valid latest successed model\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.06\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.05\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.057\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.055\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.068\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.053\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.06\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.044\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.053\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.055\n","Valid n:1000, Median progress: 2.00, Median reward: 0.00, Win rate : 0.05\n","Episode: [50000/200], Median progress: 6.50, Median reward: -0.70, Win rate : 0.25, Epsilon: 0.94\n","valid latest successed model\n","Valid n:1000, Median progress: 3.00, Median reward: 0.60, Win rate : 0.2\n","Valid n:1000, Median progress: 3.50, Median reward: 0.60, Win rate : 0.182\n","Valid n:1000, Median progress: 4.00, Median reward: 0.60, Win rate : 0.247\n","Valid n:1000, Median progress: 4.00, Median reward: 0.60, Win rate : 0.264\n","Valid n:1000, Median progress: 3.00, Median reward: 0.60, Win rate : 0.217\n","Valid n:1000, Median progress: 4.00, Median reward: 0.60, Win rate : 0.269\n","Valid n:1000, Median progress: 4.00, Median reward: 0.60, Win rate : 0.257\n","Valid n:1000, Median progress: 3.00, Median reward: 0.60, Win rate : 0.205\n","Valid n:1000, Median progress: 4.00, Median reward: 0.60, Win rate : 0.265\n","Valid n:1000, Median progress: 4.00, Median reward: 0.60, Win rate : 0.203\n","Valid n:1000, Median progress: 3.00, Median reward: 0.90, Win rate : 0.279\n","Episode: [50000/300], Median progress: 6.00, Median reward: -0.70, Win rate : 0.28, Epsilon: 0.92\n","valid latest successed model\n","Valid n:1000, Median progress: 4.00, Median reward: 0.90, Win rate : 0.307\n","Valid n:1000, Median progress: 4.00, Median reward: 1.00, Win rate : 0.288\n","Valid n:1000, Median progress: 4.00, Median reward: 0.90, Win rate : 0.291\n","Valid n:1000, Median progress: 3.00, Median reward: 0.60, Win rate : 0.276\n","Valid n:1000, Median progress: 3.00, Median reward: 0.90, Win rate : 0.303\n","Valid n:1000, Median progress: 3.00, Median reward: 0.60, Win rate : 0.287\n","Valid n:1000, Median progress: 4.00, Median reward: 0.60, Win rate : 0.306\n","Valid n:1000, Median progress: 3.00, Median reward: 0.80, Win rate : 0.274\n","Valid n:1000, Median progress: 3.00, Median reward: 0.60, Win rate : 0.265\n","Valid n:1000, Median progress: 3.00, Median reward: 0.60, Win rate : 0.237\n","Valid n:1000, Median progress: 3.00, Median reward: 0.90, Win rate : 0.304\n","Episode: [50000/400], Median progress: 5.00, Median reward: -0.70, Win rate : 0.23, Epsilon: 0.91\n","Episode: [50000/500], Median progress: 6.00, Median reward: -0.40, Win rate : 0.30, Epsilon: 0.89\n","valid latest successed model\n","Valid n:1000, Median progress: 4.00, Median reward: 1.30, Win rate : 0.474\n","Valid n:1000, Median progress: 4.00, Median reward: 1.30, Win rate : 0.449\n","Valid n:1000, Median progress: 3.00, Median reward: 1.00, Win rate : 0.402\n","Valid n:1000, Median progress: 4.00, Median reward: 1.20, Win rate : 0.438\n","Valid n:1000, Median progress: 4.00, Median reward: 1.20, Win rate : 0.476\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-9-8737a57b5b0e\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 196\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m                     UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 196\u001b[0;31m trainer = Trainer(env=env,\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mtester_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtester_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Minesweeper [RL]/codes/trainer/validShutDown.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, agent, tester_agent, name, train_start, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 57\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Minesweeper [RL]/codes/trainer/validShutDown.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_valid\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mvalid_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 130\u001b[0;31m                 \u001b[0mvalid_win_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtester_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_valid\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Minesweeper [RL]/codes/trainer/validShutDown.py\u001b[0m in \u001b[0;36mvalid_model\u001b[0;34m(self, env, agent, episode, epoch, model_state)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 159\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-9-8737a57b5b0e\u003e\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 state = torch.tensor(state.reshape(1,1,self.env.nrows,self.env.ncols),\n\u001b[1;32m     60\u001b[0m                                      dtype=torch.float32).to(device)\n\u001b[0;32m---\u003e 61\u001b[0;31m                 \u001b[0mtotal_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mtotal_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Minesweeper [RL]/codes/net/basicWithBias.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--\u003e 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class Agent:\n","    def __init__(self, env, net, **kwargs):\n","        self.env = env\n","\n","        # Environment Settings\n","        self.mem_size = kwargs.get(\"MEM_SIZE\")\n","        self.mem_size_min = kwargs.get(\"MEM_SIZE_MIN\")\n","\n","        # Learning Settings\n","        self.batch_size = kwargs.get(\"BATCH_SIZE\")\n","        self.learning_rate = kwargs.get(\"LEARNING_RATE\")\n","        self.learn_decay = kwargs.get(\"LEARN_DECAY\")\n","        self.learn_min = kwargs.get(\"LEARN_MIN\")\n","        self.discount = kwargs.get(\"DISCOUNT\")\n","\n","        # Exploration Settings\n","        self.epsilon = kwargs.get(\"EPSILON\")\n","        self.epsilon_decay = kwargs.get(\"EPSILON_DECAY\")\n","        self.epsilon_min = kwargs.get(\"EPSILON_MIN\")\n","\n","        # loss\n","        self.loss_fn = nn.MSELoss()\n","        self.losses = []\n","\n","        # target net update\n","        self.target_update_counter = 0\n","        self.update_target_baseline = kwargs.get(\"UPDATE_TARGET_EVERY\")\n","\n","        # def model\n","        self.model = copy.deepcopy(net)\n","        self.target_model = copy.deepcopy(net)\n","\n","        self.target_model.load_state_dict(self.model.state_dict())\n","\n","        self.model.to(device)\n","        self.target_model.to(device)\n","\n","        # replay memory\n","        self.replay_memory = deque(maxlen=self.mem_size)\n","\n","    def update_target_model(self):\n","        self.target_model.load_state_dict(self.model.state_dict())\n","\n","    def update_replay_memory(self, transition):\n","        self.replay_memory.append(transition)\n","\n","    def get_action(self, state):\n","        '''\n","        get_action은 하나의 state_img만을 받는다.\n","        '''\n","        if np.random.random() \u003c self.epsilon:\n","            # take random action\n","            action = np.random.choice(range(self.env.total_tiles))\n","\n","        else:\n","            self.model.eval()\n","\n","            with torch.no_grad():\n","                state = torch.tensor(state.reshape(1,1,self.env.nrows,self.env.ncols),\n","                                     dtype=torch.float32).to(device)\n","                total_action = self.model(state).view(-1)\n","                total_action = total_action.cpu()\n","\n","                self.total_action = total_action\n","\n","                action = torch.argmax(total_action).item()\n","\n","        return action\n","\n","    def train(self, done):\n","        if len(self.replay_memory) \u003c self.mem_size_min:\n","            # print(len(self.replay_memory))\n","            # print(\"Not enough data\")\n","            return\n","\n","        # optimizer\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-4)\n","\n","        self.model.train()\n","        self.target_model.eval()\n","\n","        # 리플레이 메모리에서 배치 사이즈만큼 데이터를 꺼낸다.\n","        # batch[i] = (current_state, action, reward, next_state, done)\n","        batch = random.sample(self.replay_memory, self.batch_size)\n","\n","        # 배치 안에 저장되어 있는 정보 꺼내기\n","        current_states, batched_actions, batched_rewards, next_states, batched_dones = zip(*batch)\n","\n","        # state 정의\n","        current_states = torch.tensor(np.array(current_states), dtype=torch.float32, device=device).reshape(-1,1,self.env.nrows,self.env.ncols)\n","        next_states = torch.tensor(np.array(next_states), dtype=torch.float32, device=device).reshape(-1,1,self.env.nrows,self.env.ncols)\n","\n","        action_batch = torch.tensor(batched_actions, device=device).reshape(-1,1) # reshape 안해주면 index로써 사용할 수 없다.\n","        reward_batch = torch.tensor(batched_rewards, device=device).reshape(-1,1)\n","        done_batch = torch.tensor(batched_dones, dtype=torch.float32, device=device).reshape(-1,1) # bool -\u003e 0/1\n","\n","        # Q(s,a) 값을 예측값으로 사용 - (batch, action_space.n)\n","        pred_q_values = self.model(current_states).gather(1, action_batch) # action idx의 데이터만 꺼냄\n","\n","        # kokokara\n","        # print(\"33\")\n","        # for i in range(self.batch_size):\n","        #     print(self.model(current_states)[i])\n","        # print(action_batch)\n","        # print(pred_q_values)\n","        # kokomade\n","\n","        # target 값 계산 : reward + gamma * Q(s',a')\n","        with torch.no_grad():\n","            next_q_values = self.target_model(next_states).max(1).values.reshape(-1,1)\n","            # print(\"next_q_values\")\n","            # print(next_q_values)\n","            # print(next_q_values.shape)\n","            target_q_values = reward_batch + (torch.ones(next_q_values.shape, device=device) - done_batch) * self.discount * next_q_values\n","            # print(\"target_q_values\")\n","            # print(target_q_values)\n","            # print(target_q_values.shape)\n","\n","        # kokokara\n","        # print(\"--\")\n","        # print(pred_q_values.requires_grad)\n","        # print(target_q_values.requires_grad)\n","        # kokomade\n","        loss = self.loss_fn(pred_q_values, target_q_values)\n","\n","        running_loss = loss.item()\n","        self.losses.append(round(running_loss,6))\n","\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        if done:\n","            self.target_update_counter += 1\n","\n","        if self.target_update_counter == self.update_target_baseline:\n","            self.update_target_model()\n","            self.target_update_counter = 0\n","\n","        # decay learning rate\n","        self.learning_rate = max(self.learn_min, self.learning_rate*self.learn_decay)\n","\n","        # decay epsilon\n","        self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)\n","\n","class Limited18Agent(Agent):\n","    def __init__(self, env, net, replay_memory=False, **kwargs):\n","        super().__init__(env, net, **kwargs)\n","        # 불러올 리플레이 메모리가 있다면 불러옴\n","        if replay_memory:\n","            self.replay_memory = replay_memory\n","\n","    def update_replay_memory(self, transition):\n","        current_state = transition[0]\n","\n","        if np.sum(current_state != self.env.unrevealed) \u003e= 18: # 경험적인 데이터 18(나름 하이퍼파라미터긴 함ㅋ)\n","            self.replay_memory.append(transition)\n","\n","env = MinesweeperEnv(map_size=(4,4),\n","                     n_mines=2,\n","                     rewards={'win':1, 'lose':-1, 'progress':0.3, 'guess':0.3, 'no_progress' : -0.3})\n","\n","\n","net = Net(input_dims=env.state.shape,\n","          n_actions=env.total_tiles,\n","          conv_units=CONV_UNITS)\n","\n","agent = Agent(env=env,\n","                        net=net,\n","                        MEM_SIZE=MEM_SIZE,\n","                        MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                        BATCH_SIZE=BATCH_SIZE,\n","                        LEARNING_RATE=LEARNING_RATE,\n","                        LEARN_DECAY=LEARN_DECAY,\n","                        LEARN_MIN=LEARN_MIN,\n","                        DISCOUNT=DISCOUNT,\n","                        EPSILON=EPSILON,\n","                        EPSILON_DECAY=EPSILON_DECAY,\n","                        EPSILON_MIN=EPSILON_MIN,\n","                        UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)\n","\n","tester_agent = Agent(env=env,\n","                    net=net,\n","                    MEM_SIZE=MEM_SIZE,\n","                    MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                    BATCH_SIZE=BATCH_SIZE,\n","                    LEARNING_RATE=LEARNING_RATE,\n","                    LEARN_DECAY=LEARN_DECAY,\n","                    LEARN_MIN=LEARN_MIN,\n","                    DISCOUNT=DISCOUNT,\n","                    EPSILON=EPSILON,\n","                    EPSILON_DECAY=EPSILON_DECAY,\n","                    EPSILON_MIN=EPSILON_MIN,\n","                    UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)\n","\n","trainer = Trainer(env=env,\n","                    agent=agent,\n","                    tester_agent=tester_agent,\n","                    name='limited_scalar',\n","                    train_start=True,\n","                    EPISODES = EPISODES,\n","                    PRINT_INTERVAL = PRINT_INTERVAL,\n","                    TRAIN_RENDER = TRAIN_RENDER,\n","                    TRAIN_TIMESTEP = TRAIN_TIMESTEPS[0],\n","                    VIUSAL_INTERVAL = VIUSAL_INTERVAL,\n","                    VALID_SAMPLE = VALID_SAMPLE,\n","                    VALID_INTERVAL = VALID_INTERVAL)"]},{"cell_type":"markdown","metadata":{"id":"TSbDwBaZgg46"},"source":["# 02 Train, Valid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YIE1PWMO1Sm"},"outputs":[],"source":["env = MinesweeperEnv(map_size=level['easy']['map_size'],\n","                     n_mines=level['easy']['n_mines'],\n","                     rewards={'win':1, 'lose':-1, 'progress':0.3, 'guess':-0.3, 'no_progress' : -0.3})\n","\n","# env = LimitedMinesweeperEnv(map_size=level['easy']['map_size'],\n","#                             n_mines=level['easy']['n_mines'])\n","\n","\n","net = Net(input_dims=env.state.shape,\n","          n_actions=env.total_tiles,\n","          conv_units=CONV_UNITS)\n","\n","agent = Limited18Agent(env=env,\n","                        net=net,\n","                        MEM_SIZE=MEM_SIZE,\n","                        MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                        BATCH_SIZE=BATCH_SIZE,\n","                        LEARNING_RATE=LEARNING_RATE,\n","                        LEARN_DECAY=LEARN_DECAY,\n","                        LEARN_MIN=LEARN_MIN,\n","                        DISCOUNT=DISCOUNT,\n","                        EPSILON=EPSILON,\n","                        EPSILON_DECAY=EPSILON_DECAY,\n","                        EPSILON_MIN=EPSILON_MIN,\n","                        UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)"]},{"cell_type":"markdown","metadata":{"id":"7L5dNbnpiYjH"},"source":["## TRAIN_PARAMETERS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6p9LbiVfjFvA"},"outputs":[],"source":["EPISODES = 100000\n","PRINT_INTERVAL = 100\n","TRAIN_RENDER = False\n","\n","TRAIN_TIMESTEPS = ['every timestep', 'every episodes']\n","TRAIN_TIMESTEP = TRAIN_TIMESTEPS[0]\n","VIUSAL_INTERVAL = 100\n","\n","VALID_SAMPLE = 1000\n","VALID_INTERVAL = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WSW8m6WyJq_E"},"outputs":[],"source":["tester_agent = Agent(env=env,\n","                    net=net,\n","                    MEM_SIZE=MEM_SIZE,\n","                    MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                    BATCH_SIZE=BATCH_SIZE,\n","                    LEARNING_RATE=LEARNING_RATE,\n","                    LEARN_DECAY=LEARN_DECAY,\n","                    LEARN_MIN=LEARN_MIN,\n","                    DISCOUNT=DISCOUNT,\n","                    EPSILON=EPSILON,\n","                    EPSILON_DECAY=EPSILON_DECAY,\n","                    EPSILON_MIN=EPSILON_MIN,\n","                    UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"rspyTPvlJk2B"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: [100000/100], Median progress: 7.00, Median reward: -2.35, Win rate : 0.00, Epsilon: 0.95\n","Episode: [100000/200], Median progress: 6.50, Median reward: -2.50, Win rate : 0.00, Epsilon: 0.94\n","Episode: [100000/300], Median progress: 6.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.92\n","Episode: [100000/400], Median progress: 7.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.90\n","Episode: [100000/500], Median progress: 7.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.88\n","Episode: [100000/600], Median progress: 7.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.85\n","Episode: [100000/700], Median progress: 6.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.84\n","Episode: [100000/800], Median progress: 6.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.82\n","Episode: [100000/900], Median progress: 6.50, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.80\n","Episode: [100000/1000], Median progress: 7.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.78\n","Episode: [100000/1100], Median progress: 8.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.76\n","Episode: [100000/1200], Median progress: 6.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.75\n","Episode: [100000/1300], Median progress: 6.50, Median reward: -2.05, Win rate : 0.01, Epsilon: 0.73\n","valid latest successed model\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.60, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.60, Win rate : 0.0\n","Valid n:1000, Median progress: 4.00, Median reward: -0.60, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 3.00, Median reward: -0.30, Win rate : 0.0\n","Episode: [100000/1400], Median progress: 6.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.71\n","Episode: [100000/1500], Median progress: 8.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.69\n","Episode: [100000/1600], Median progress: 7.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.68\n","Episode: [100000/1700], Median progress: 7.00, Median reward: -2.20, Win rate : 0.00, Epsilon: 0.66\n","Episode: [100000/1800], Median progress: 8.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.64\n","Episode: [100000/1900], Median progress: 5.50, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.63\n","Episode: [100000/2000], Median progress: 7.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.61\n","Episode: [100000/2100], Median progress: 8.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.59\n","Episode: [100000/2200], Median progress: 6.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.58\n","Episode: [100000/2300], Median progress: 7.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.57\n","Episode: [100000/2400], Median progress: 6.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.55\n","Episode: [100000/2500], Median progress: 7.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.53\n","Episode: [100000/2600], Median progress: 9.00, Median reward: -2.20, Win rate : 0.01, Epsilon: 0.51\n","Episode: [100000/2700], Median progress: 7.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.50\n","Episode: [100000/2800], Median progress: 6.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.49\n","Episode: [100000/2900], Median progress: 6.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.47\n","Episode: [100000/3000], Median progress: 7.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.46\n","Episode: [100000/3100], Median progress: 7.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.45\n","Episode: [100000/3200], Median progress: 8.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.43\n","Episode: [100000/3300], Median progress: 6.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.42\n","Episode: [100000/3400], Median progress: 8.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.41\n","Episode: [100000/3500], Median progress: 8.00, Median reward: -1.75, Win rate : 0.00, Epsilon: 0.40\n","Episode: [100000/3600], Median progress: 5.50, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.38\n","Episode: [100000/3700], Median progress: 10.00, Median reward: -1.75, Win rate : 0.00, Epsilon: 0.37\n","Episode: [100000/3800], Median progress: 10.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.35\n","Episode: [100000/3900], Median progress: 10.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.34\n","Episode: [100000/4000], Median progress: 8.00, Median reward: -1.90, Win rate : 0.00, Epsilon: 0.33\n","Episode: [100000/4100], Median progress: 8.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.31\n","Episode: [100000/4200], Median progress: 10.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.30\n","Episode: [100000/4300], Median progress: 8.50, Median reward: -1.60, Win rate : 0.01, Epsilon: 0.29\n","Episode: [100000/4400], Median progress: 7.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.28\n","Episode: [100000/4500], Median progress: 6.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.27\n","Episode: [100000/4600], Median progress: 9.50, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.25\n","Episode: [100000/4700], Median progress: 6.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.25\n","Episode: [100000/4800], Median progress: 8.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.23\n","Episode: [100000/4900], Median progress: 8.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.22\n","Episode: [100000/5000], Median progress: 10.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.21\n","Episode: [100000/5100], Median progress: 8.00, Median reward: -1.45, Win rate : 0.00, Epsilon: 0.20\n","Episode: [100000/5200], Median progress: 9.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.19\n","Episode: [100000/5300], Median progress: 11.00, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.18\n","Episode: [100000/5400], Median progress: 8.50, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.18\n","Episode: [100000/5500], Median progress: 11.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.17\n","Episode: [100000/5600], Median progress: 10.00, Median reward: -1.60, Win rate : 0.02, Epsilon: 0.16\n","valid latest successed model\n","Valid n:1000, Median progress: 5.00, Median reward: 0.00, Win rate : 0.0\n","Valid n:1000, Median progress: 5.00, Median reward: -0.00, Win rate : 0.0\n","Valid n:1000, Median progress: 6.00, Median reward: 0.00, Win rate : 0.0\n","Valid n:1000, Median progress: 5.00, Median reward: -0.10, Win rate : 0.0\n","Valid n:1000, Median progress: 5.00, Median reward: -0.30, Win rate : 0.001\n","Valid n:1000, Median progress: 5.00, Median reward: -0.10, Win rate : 0.001\n","Valid n:1000, Median progress: 5.00, Median reward: -0.30, Win rate : 0.001\n","Valid n:1000, Median progress: 5.00, Median reward: -0.20, Win rate : 0.0\n","Valid n:1000, Median progress: 5.00, Median reward: -0.30, Win rate : 0.001\n","Valid n:1000, Median progress: 5.00, Median reward: -0.10, Win rate : 0.0\n","Valid n:1000, Median progress: 5.00, Median reward: -0.30, Win rate : 0.0\n","Episode: [100000/5700], Median progress: 9.00, Median reward: -1.45, Win rate : 0.00, Epsilon: 0.15\n","Episode: [100000/5800], Median progress: 11.50, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.14\n","Episode: [100000/5900], Median progress: 8.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.13\n","Episode: [100000/6000], Median progress: 7.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.12\n","Episode: [100000/6100], Median progress: 14.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.11\n","Episode: [100000/6200], Median progress: 11.00, Median reward: -1.60, Win rate : 0.00, Epsilon: 0.10\n","Episode: [100000/6300], Median progress: 8.00, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.09\n","Episode: [100000/6400], Median progress: 9.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.09\n","Episode: [100000/6500], Median progress: 12.50, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.08\n","Episode: [100000/6600], Median progress: 12.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.07\n","Episode: [100000/6700], Median progress: 9.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.07\n","Episode: [100000/6800], Median progress: 15.00, Median reward: -2.35, Win rate : 0.00, Epsilon: 0.06\n","Episode: [100000/6900], Median progress: 10.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.05\n","Episode: [100000/7000], Median progress: 10.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.05\n","Episode: [100000/7100], Median progress: 13.00, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.04\n","Episode: [100000/7200], Median progress: 10.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.03\n","Episode: [100000/7300], Median progress: 9.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.03\n","Episode: [100000/7400], Median progress: 14.00, Median reward: -1.60, Win rate : 0.01, Epsilon: 0.02\n","Episode: [100000/7500], Median progress: 11.50, Median reward: -1.60, Win rate : 0.01, Epsilon: 0.02\n","Episode: [100000/7600], Median progress: 11.50, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/7700], Median progress: 25.00, Median reward: -5.65, Win rate : 0.00, Epsilon: 0.01\n","Episode: [100000/7800], Median progress: 9.50, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.01\n","Episode: [100000/7900], Median progress: 10.00, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/8000], Median progress: 11.50, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 6.00, Median reward: 0.00, Win rate : 0.003\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.003\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.001\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.002\n","Valid n:1000, Median progress: 6.00, Median reward: 0.00, Win rate : 0.003\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.002\n","Valid n:1000, Median progress: 6.00, Median reward: 0.00, Win rate : 0.0\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.0\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.002\n","Valid n:1000, Median progress: 6.50, Median reward: 0.20, Win rate : 0.001\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.001\n","Episode: [100000/8100], Median progress: 15.00, Median reward: -1.60, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/8200], Median progress: 9.00, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/8300], Median progress: 26.50, Median reward: -3.25, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/8400], Median progress: 11.50, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/8500], Median progress: 14.50, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/8600], Median progress: 50.50, Median reward: -10.60, Win rate : 0.07, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 8.00, Median reward: 0.50, Win rate : 0.002\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.002\n","Valid n:1000, Median progress: 7.00, Median reward: 0.10, Win rate : 0.002\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.002\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.002\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.001\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.001\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.002\n","Valid n:1000, Median progress: 7.00, Median reward: 0.00, Win rate : 0.001\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.002\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.0\n","Episode: [100000/8700], Median progress: 11.00, Median reward: -1.30, Win rate : 0.00, Epsilon: 0.01\n","Episode: [100000/8800], Median progress: 11.50, Median reward: -1.60, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/8900], Median progress: 50.00, Median reward: -10.60, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/9000], Median progress: 14.50, Median reward: -1.75, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/9100], Median progress: 10.00, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/9200], Median progress: 14.50, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/9300], Median progress: 12.50, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/9400], Median progress: 18.50, Median reward: -1.90, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/9500], Median progress: 13.50, Median reward: -1.30, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/9600], Median progress: 13.50, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/9700], Median progress: 36.50, Median reward: -6.25, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/9800], Median progress: 14.00, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/9900], Median progress: 15.00, Median reward: -1.45, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/10000], Median progress: 7.50, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/10100], Median progress: 12.50, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/10200], Median progress: 13.00, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/10300], Median progress: 16.00, Median reward: -1.30, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/10400], Median progress: 12.50, Median reward: -1.30, Win rate : 0.08, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.005\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.01\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.006\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.005\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.006\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.008\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.004\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.006\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.004\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.003\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.006\n","Episode: [100000/10500], Median progress: 13.50, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/10600], Median progress: 41.00, Median reward: -5.55, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/10700], Median progress: 13.50, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/10800], Median progress: 39.50, Median reward: -7.75, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/10900], Median progress: 21.50, Median reward: -1.75, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/11000], Median progress: 10.00, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/11100], Median progress: 27.50, Median reward: -2.20, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/11200], Median progress: 12.00, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/11300], Median progress: 40.50, Median reward: -8.95, Win rate : 0.09, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.003\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.004\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.004\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.005\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.006\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.0\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.008\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.01\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.007\n","Valid n:1000, Median progress: 7.00, Median reward: 0.20, Win rate : 0.003\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.006\n","Episode: [100000/11400], Median progress: 22.50, Median reward: -2.95, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/11500], Median progress: 26.00, Median reward: -6.70, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/11600], Median progress: 25.50, Median reward: -5.65, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/11700], Median progress: 42.00, Median reward: -9.10, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/11800], Median progress: 56.50, Median reward: -12.55, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/11900], Median progress: 65.00, Median reward: -15.15, Win rate : 0.10, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 6.00, Median reward: 0.10, Win rate : 0.003\n","Valid n:1000, Median progress: 6.00, Median reward: 0.00, Win rate : 0.005\n","Valid n:1000, Median progress: 6.00, Median reward: 0.00, Win rate : 0.009\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.007\n","Valid n:1000, Median progress: 5.00, Median reward: -0.10, Win rate : 0.004\n","Valid n:1000, Median progress: 6.00, Median reward: 0.30, Win rate : 0.008\n","Valid n:1000, Median progress: 6.00, Median reward: 0.10, Win rate : 0.004\n","Valid n:1000, Median progress: 6.00, Median reward: 0.00, Win rate : 0.005\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.003\n","Valid n:1000, Median progress: 6.00, Median reward: 0.30, Win rate : 0.007\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.005\n","Episode: [100000/12000], Median progress: 18.50, Median reward: -1.60, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/12100], Median progress: 15.00, Median reward: -1.30, Win rate : 0.08, Epsilon: 0.01\n","Episode: [100000/12200], Median progress: 31.00, Median reward: -5.80, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/12300], Median progress: 20.50, Median reward: -1.30, Win rate : 0.11, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.003\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.005\n","Valid n:1000, Median progress: 5.00, Median reward: 0.00, Win rate : 0.002\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.009\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.009\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.006\n","Valid n:1000, Median progress: 7.00, Median reward: 0.40, Win rate : 0.005\n","Valid n:1000, Median progress: 7.00, Median reward: 0.55, Win rate : 0.005\n","Valid n:1000, Median progress: 5.00, Median reward: 0.00, Win rate : 0.004\n","Valid n:1000, Median progress: 6.00, Median reward: 0.20, Win rate : 0.011\n","Valid n:1000, Median progress: 5.00, Median reward: 0.00, Win rate : 0.003\n","Episode: [100000/12400], Median progress: 82.00, Median reward: -21.85, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/12500], Median progress: 11.00, Median reward: -1.30, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/12600], Median progress: 37.50, Median reward: -8.80, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/12700], Median progress: 10.00, Median reward: -1.30, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/12800], Median progress: 23.50, Median reward: -2.05, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/12900], Median progress: 81.50, Median reward: -20.05, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/13000], Median progress: 24.50, Median reward: -5.35, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/13100], Median progress: 42.00, Median reward: -9.25, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/13200], Median progress: 31.00, Median reward: -2.20, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/13300], Median progress: 21.50, Median reward: -1.90, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/13400], Median progress: 13.00, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/13500], Median progress: 19.00, Median reward: -1.60, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/13600], Median progress: 43.00, Median reward: -9.40, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/13700], Median progress: 22.50, Median reward: -1.90, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/13800], Median progress: 31.50, Median reward: -5.95, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/13900], Median progress: 16.00, Median reward: -1.45, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/14000], Median progress: 11.00, Median reward: -1.30, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/14100], Median progress: 11.00, Median reward: -1.30, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/14200], Median progress: 19.00, Median reward: -1.30, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/14300], Median progress: 47.50, Median reward: -10.60, Win rate : 0.02, Epsilon: 0.01\n","Episode: [100000/14400], Median progress: 91.00, Median reward: -21.45, Win rate : 0.08, Epsilon: 0.01\n","Episode: [100000/14500], Median progress: 61.50, Median reward: -14.65, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/14600], Median progress: 40.00, Median reward: -9.85, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/14700], Median progress: 12.00, Median reward: -2.20, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/14800], Median progress: 12.00, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/14900], Median progress: 10.50, Median reward: -1.30, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/15000], Median progress: 22.00, Median reward: -1.45, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/15100], Median progress: 31.00, Median reward: -3.25, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/15200], Median progress: 12.00, Median reward: -1.30, Win rate : 0.08, Epsilon: 0.01\n","Episode: [100000/15300], Median progress: 24.00, Median reward: -1.45, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/15400], Median progress: 14.50, Median reward: -1.30, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/15500], Median progress: 9.00, Median reward: -1.15, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/15600], Median progress: 21.50, Median reward: -2.50, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/15700], Median progress: 16.00, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/15800], Median progress: 10.50, Median reward: -1.30, Win rate : 0.04, Epsilon: 0.01\n","Episode: [100000/15900], Median progress: 26.50, Median reward: -1.75, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/16000], Median progress: 16.50, Median reward: -1.30, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/16100], Median progress: 16.00, Median reward: -1.30, Win rate : 0.08, Epsilon: 0.01\n","Episode: [100000/16200], Median progress: 13.00, Median reward: -1.30, Win rate : 0.01, Epsilon: 0.01\n","Episode: [100000/16300], Median progress: 28.00, Median reward: -2.50, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/16400], Median progress: 10.00, Median reward: -1.30, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/16500], Median progress: 11.50, Median reward: -1.60, Win rate : 0.03, Epsilon: 0.01\n","Episode: [100000/16600], Median progress: 15.50, Median reward: -1.30, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/16700], Median progress: 37.00, Median reward: -7.45, Win rate : 0.08, Epsilon: 0.01\n","Episode: [100000/16800], Median progress: 9.50, Median reward: -1.30, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/16900], Median progress: 17.50, Median reward: -1.90, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/17000], Median progress: 11.00, Median reward: -1.30, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/17100], Median progress: 14.00, Median reward: -1.30, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/17200], Median progress: 14.00, Median reward: -1.30, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/17300], Median progress: 28.00, Median reward: -5.95, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/17400], Median progress: 17.00, Median reward: -1.60, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/17500], Median progress: 17.00, Median reward: -1.60, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/17600], Median progress: 10.00, Median reward: -1.30, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/17700], Median progress: 11.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 7.00, Median reward: 0.60, Win rate : 0.016\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.02\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.017\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.019\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.025\n","Valid n:1000, Median progress: 7.00, Median reward: 0.60, Win rate : 0.033\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.019\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.027\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.02\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.016\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.021\n","Episode: [100000/17800], Median progress: 10.50, Median reward: -1.30, Win rate : 0.05, Epsilon: 0.01\n","Episode: [100000/17900], Median progress: 14.50, Median reward: -1.30, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/18000], Median progress: 22.00, Median reward: -2.80, Win rate : 0.13, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.016\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.017\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.013\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.015\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.018\n","Valid n:1000, Median progress: 7.00, Median reward: 0.55, Win rate : 0.021\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.019\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.015\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.013\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.021\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.017\n","Episode: [100000/18100], Median progress: 12.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/18200], Median progress: 13.50, Median reward: -1.45, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/18300], Median progress: 19.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/18400], Median progress: 28.50, Median reward: -3.55, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/18500], Median progress: 70.50, Median reward: -14.65, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/18600], Median progress: 12.00, Median reward: -1.30, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/18700], Median progress: 14.50, Median reward: -1.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/18800], Median progress: 50.00, Median reward: -10.30, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/18900], Median progress: 11.50, Median reward: -1.30, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/19000], Median progress: 12.00, Median reward: -1.30, Win rate : 0.16, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.019\n","Valid n:1000, Median progress: 7.00, Median reward: 0.60, Win rate : 0.017\n","Valid n:1000, Median progress: 7.00, Median reward: 0.60, Win rate : 0.033\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.018\n","Valid n:1000, Median progress: 7.00, Median reward: 0.60, Win rate : 0.02\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.028\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.015\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.02\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.029\n","Valid n:1000, Median progress: 7.00, Median reward: 0.60, Win rate : 0.02\n","Valid n:1000, Median progress: 7.00, Median reward: 0.60, Win rate : 0.02\n","Episode: [100000/19100], Median progress: 15.50, Median reward: -1.30, Win rate : 0.08, Epsilon: 0.01\n","Episode: [100000/19200], Median progress: 27.00, Median reward: -3.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/19300], Median progress: 48.50, Median reward: -9.60, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/19400], Median progress: 15.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/19500], Median progress: 18.50, Median reward: -1.60, Win rate : 0.10, Epsilon: 0.01\n","Episode: [100000/19600], Median progress: 13.50, Median reward: -1.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/19700], Median progress: 40.50, Median reward: -8.20, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/19800], Median progress: 21.00, Median reward: -2.20, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/19900], Median progress: 28.50, Median reward: -1.90, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/20000], Median progress: 50.50, Median reward: -10.45, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/20100], Median progress: 24.50, Median reward: -2.40, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/20200], Median progress: 19.00, Median reward: -1.30, Win rate : 0.14, Epsilon: 0.01\n","Episode: [100000/20300], Median progress: 26.00, Median reward: -2.50, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/20400], Median progress: 16.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/20500], Median progress: 15.00, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/20600], Median progress: 35.50, Median reward: -3.85, Win rate : 0.23, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.029\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.036\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.04\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.034\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.036\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.037\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.029\n","Valid n:1000, Median progress: 8.00, Median reward: 0.30, Win rate : 0.045\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.026\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.043\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.028\n","Episode: [100000/20700], Median progress: 42.50, Median reward: -6.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/20800], Median progress: 13.50, Median reward: -1.30, Win rate : 0.09, Epsilon: 0.01\n","Episode: [100000/20900], Median progress: 16.00, Median reward: -1.30, Win rate : 0.16, Epsilon: 0.01\n","Episode: [100000/21000], Median progress: 12.00, Median reward: -1.30, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/21100], Median progress: 33.00, Median reward: -5.95, Win rate : 0.14, Epsilon: 0.01\n","Episode: [100000/21200], Median progress: 16.50, Median reward: -1.30, Win rate : 0.11, Epsilon: 0.01\n","Episode: [100000/21300], Median progress: 12.50, Median reward: -1.30, Win rate : 0.06, Epsilon: 0.01\n","Episode: [100000/21400], Median progress: 11.00, Median reward: -1.30, Win rate : 0.07, Epsilon: 0.01\n","Episode: [100000/21500], Median progress: 17.00, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/21600], Median progress: 13.50, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/21700], Median progress: 20.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/21800], Median progress: 10.00, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/21900], Median progress: 18.00, Median reward: -1.30, Win rate : 0.14, Epsilon: 0.01\n","Episode: [100000/22000], Median progress: 17.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/22100], Median progress: 17.00, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/22200], Median progress: 14.00, Median reward: -1.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/22300], Median progress: 13.00, Median reward: -1.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/22400], Median progress: 24.00, Median reward: -1.45, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/22500], Median progress: 16.50, Median reward: -1.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/22600], Median progress: 14.50, Median reward: -1.00, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/22700], Median progress: 17.00, Median reward: -1.80, Win rate : 0.14, Epsilon: 0.01\n","Episode: [100000/22800], Median progress: 14.50, Median reward: -1.30, Win rate : 0.14, Epsilon: 0.01\n","Episode: [100000/22900], Median progress: 25.00, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/23000], Median progress: 21.50, Median reward: -1.30, Win rate : 0.12, Epsilon: 0.01\n","Episode: [100000/23100], Median progress: 14.00, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/23200], Median progress: 13.00, Median reward: -1.15, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/23300], Median progress: 14.00, Median reward: -1.00, Win rate : 0.14, Epsilon: 0.01\n","Episode: [100000/23400], Median progress: 15.00, Median reward: -1.30, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/23500], Median progress: 20.00, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/23600], Median progress: 15.50, Median reward: -1.30, Win rate : 0.21, Epsilon: 0.01\n","Episode: [100000/23700], Median progress: 18.00, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/23800], Median progress: 18.00, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/23900], Median progress: 29.50, Median reward: -3.85, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/24000], Median progress: 48.50, Median reward: -6.90, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/24100], Median progress: 15.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.049\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.058\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.055\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.044\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.055\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.03\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.056\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.051\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.053\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.052\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.045\n","Episode: [100000/24200], Median progress: 31.50, Median reward: -3.35, Win rate : 0.25, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.056\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.057\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.054\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.048\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.053\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.051\n","Valid n:1000, Median progress: 7.50, Median reward: 0.60, Win rate : 0.044\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.031\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.054\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.043\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.068\n","Episode: [100000/24300], Median progress: 17.50, Median reward: -1.30, Win rate : 0.19, Epsilon: 0.01\n","Episode: [100000/24400], Median progress: 16.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/24500], Median progress: 31.50, Median reward: -2.05, Win rate : 0.23, Epsilon: 0.01\n","Episode: [100000/24600], Median progress: 10.50, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/24700], Median progress: 15.00, Median reward: -1.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/24800], Median progress: 17.50, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/24900], Median progress: 12.00, Median reward: -1.15, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/25000], Median progress: 19.50, Median reward: -1.30, Win rate : 0.26, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.055\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.062\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.066\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.054\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.044\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.06\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.057\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.047\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.056\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.058\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.042\n","Episode: [100000/25100], Median progress: 16.50, Median reward: -1.00, Win rate : 0.16, Epsilon: 0.01\n","Episode: [100000/25200], Median progress: 17.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/25300], Median progress: 17.00, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/25400], Median progress: 14.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/25500], Median progress: 19.00, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/25600], Median progress: 19.00, Median reward: -1.15, Win rate : 0.16, Epsilon: 0.01\n","Episode: [100000/25700], Median progress: 18.00, Median reward: -1.30, Win rate : 0.29, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.055\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.063\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.041\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.068\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.041\n","Valid n:1000, Median progress: 7.00, Median reward: 0.50, Win rate : 0.035\n","Valid n:1000, Median progress: 7.00, Median reward: 0.30, Win rate : 0.035\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.053\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.049\n","Valid n:1000, Median progress: 8.00, Median reward: 0.80, Win rate : 0.046\n","Valid n:1000, Median progress: 8.00, Median reward: 0.60, Win rate : 0.059\n","Episode: [100000/25800], Median progress: 22.00, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/25900], Median progress: 14.50, Median reward: -1.30, Win rate : 0.13, Epsilon: 0.01\n","Episode: [100000/26000], Median progress: 27.50, Median reward: -1.30, Win rate : 0.23, Epsilon: 0.01\n","Episode: [100000/26100], Median progress: 17.00, Median reward: -1.60, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/26200], Median progress: 15.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/26300], Median progress: 19.00, Median reward: -1.75, Win rate : 0.16, Epsilon: 0.01\n","Episode: [100000/26400], Median progress: 20.00, Median reward: -1.60, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/26500], Median progress: 14.50, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/26600], Median progress: 23.00, Median reward: -1.45, Win rate : 0.14, Epsilon: 0.01\n","Episode: [100000/26700], Median progress: 20.50, Median reward: -1.30, Win rate : 0.27, Epsilon: 0.01\n","Episode: [100000/26800], Median progress: 12.00, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/26900], Median progress: 10.00, Median reward: -1.00, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/27000], Median progress: 17.50, Median reward: -1.30, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/27100], Median progress: 31.50, Median reward: -3.25, Win rate : 0.21, Epsilon: 0.01\n","Episode: [100000/27200], Median progress: 17.00, Median reward: -1.30, Win rate : 0.19, Epsilon: 0.01\n","Episode: [100000/27300], Median progress: 19.00, Median reward: -1.30, Win rate : 0.21, Epsilon: 0.01\n","Episode: [100000/27400], Median progress: 20.00, Median reward: -1.30, Win rate : 0.27, Epsilon: 0.01\n","Episode: [100000/27500], Median progress: 14.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/27600], Median progress: 19.50, Median reward: -1.30, Win rate : 0.16, Epsilon: 0.01\n","Episode: [100000/27700], Median progress: 22.00, Median reward: -1.30, Win rate : 0.21, Epsilon: 0.01\n","Episode: [100000/27800], Median progress: 32.50, Median reward: -1.90, Win rate : 0.19, Epsilon: 0.01\n","Episode: [100000/27900], Median progress: 12.50, Median reward: -1.30, Win rate : 0.23, Epsilon: 0.01\n","Episode: [100000/28000], Median progress: 16.50, Median reward: -1.30, Win rate : 0.25, Epsilon: 0.01\n","Episode: [100000/28100], Median progress: 17.50, Median reward: -1.30, Win rate : 0.19, Epsilon: 0.01\n","Episode: [100000/28200], Median progress: 25.50, Median reward: -1.45, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/28300], Median progress: 16.50, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/28400], Median progress: 24.50, Median reward: -2.35, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/28500], Median progress: 22.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/28600], Median progress: 26.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/28700], Median progress: 22.50, Median reward: -1.60, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/28800], Median progress: 22.50, Median reward: -1.45, Win rate : 0.29, Epsilon: 0.01\n","Episode: [100000/28900], Median progress: 17.50, Median reward: -1.30, Win rate : 0.26, Epsilon: 0.01\n","Episode: [100000/29000], Median progress: 17.50, Median reward: -1.30, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/29100], Median progress: 29.00, Median reward: -1.80, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/29200], Median progress: 18.50, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/29300], Median progress: 21.00, Median reward: -1.60, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/29400], Median progress: 17.00, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/29500], Median progress: 14.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/29600], Median progress: 13.00, Median reward: -1.00, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/29700], Median progress: 16.00, Median reward: -0.70, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/29800], Median progress: 19.50, Median reward: -1.00, Win rate : 0.26, Epsilon: 0.01\n","Episode: [100000/29900], Median progress: 19.00, Median reward: -1.30, Win rate : 0.27, Epsilon: 0.01\n","Episode: [100000/30000], Median progress: 21.50, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/30100], Median progress: 18.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/30200], Median progress: 18.50, Median reward: -1.30, Win rate : 0.15, Epsilon: 0.01\n","Episode: [100000/30300], Median progress: 20.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/30400], Median progress: 17.00, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/30500], Median progress: 20.50, Median reward: -1.30, Win rate : 0.27, Epsilon: 0.01\n","Episode: [100000/30600], Median progress: 20.50, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/30700], Median progress: 17.50, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/30800], Median progress: 14.00, Median reward: -1.30, Win rate : 0.21, Epsilon: 0.01\n","Episode: [100000/30900], Median progress: 13.50, Median reward: -1.00, Win rate : 0.25, Epsilon: 0.01\n","Episode: [100000/31000], Median progress: 24.50, Median reward: -1.30, Win rate : 0.21, Epsilon: 0.01\n","Episode: [100000/31100], Median progress: 32.50, Median reward: -1.65, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/31200], Median progress: 20.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/31300], Median progress: 16.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/31400], Median progress: 24.00, Median reward: -1.60, Win rate : 0.23, Epsilon: 0.01\n","Episode: [100000/31500], Median progress: 12.50, Median reward: -1.30, Win rate : 0.23, Epsilon: 0.01\n","Episode: [100000/31600], Median progress: 25.50, Median reward: -1.60, Win rate : 0.35, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.077\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.075\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.087\n","Valid n:1000, Median progress: 8.00, Median reward: 0.30, Win rate : 0.072\n","Valid n:1000, Median progress: 9.00, Median reward: 0.50, Win rate : 0.08\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.087\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.081\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.079\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.076\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.093\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.076\n","Episode: [100000/31700], Median progress: 42.00, Median reward: -7.15, Win rate : 0.28, Epsilon: 0.01\n","Episode: [100000/31800], Median progress: 23.00, Median reward: -1.30, Win rate : 0.28, Epsilon: 0.01\n","Episode: [100000/31900], Median progress: 15.50, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/32000], Median progress: 17.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/32100], Median progress: 19.00, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/32200], Median progress: 29.00, Median reward: -1.50, Win rate : 0.23, Epsilon: 0.01\n","Episode: [100000/32300], Median progress: 19.50, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/32400], Median progress: 14.50, Median reward: -1.30, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/32500], Median progress: 16.00, Median reward: -1.30, Win rate : 0.20, Epsilon: 0.01\n","Episode: [100000/32600], Median progress: 14.50, Median reward: -1.30, Win rate : 0.19, Epsilon: 0.01\n","Episode: [100000/32700], Median progress: 13.50, Median reward: -1.30, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/32800], Median progress: 17.50, Median reward: -1.30, Win rate : 0.17, Epsilon: 0.01\n","Episode: [100000/32900], Median progress: 19.00, Median reward: -1.30, Win rate : 0.25, Epsilon: 0.01\n","Episode: [100000/33000], Median progress: 17.00, Median reward: -1.45, Win rate : 0.16, Epsilon: 0.01\n","Episode: [100000/33100], Median progress: 29.00, Median reward: -1.60, Win rate : 0.25, Epsilon: 0.01\n","Episode: [100000/33200], Median progress: 18.00, Median reward: -1.60, Win rate : 0.26, Epsilon: 0.01\n","Episode: [100000/33300], Median progress: 24.50, Median reward: -1.30, Win rate : 0.26, Epsilon: 0.01\n","Episode: [100000/33400], Median progress: 15.00, Median reward: -1.00, Win rate : 0.19, Epsilon: 0.01\n","Episode: [100000/33500], Median progress: 23.00, Median reward: -1.30, Win rate : 0.29, Epsilon: 0.01\n","Episode: [100000/33600], Median progress: 19.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/33700], Median progress: 14.00, Median reward: -1.30, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/33800], Median progress: 19.50, Median reward: -1.30, Win rate : 0.32, Epsilon: 0.01\n","Episode: [100000/33900], Median progress: 14.00, Median reward: -1.30, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/34000], Median progress: 14.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/34100], Median progress: 15.00, Median reward: -1.15, Win rate : 0.28, Epsilon: 0.01\n","Episode: [100000/34200], Median progress: 36.00, Median reward: -6.25, Win rate : 0.27, Epsilon: 0.01\n","Episode: [100000/34300], Median progress: 23.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/34400], Median progress: 13.50, Median reward: -1.30, Win rate : 0.18, Epsilon: 0.01\n","Episode: [100000/34500], Median progress: 17.50, Median reward: -1.30, Win rate : 0.30, Epsilon: 0.01\n","Episode: [100000/34600], Median progress: 27.50, Median reward: -2.20, Win rate : 0.22, Epsilon: 0.01\n","Episode: [100000/34700], Median progress: 22.00, Median reward: -1.30, Win rate : 0.31, Epsilon: 0.01\n","Episode: [100000/34800], Median progress: 18.50, Median reward: -0.85, Win rate : 0.34, Epsilon: 0.01\n","Episode: [100000/34900], Median progress: 17.50, Median reward: -1.30, Win rate : 0.25, Epsilon: 0.01\n","Episode: [100000/35000], Median progress: 17.50, Median reward: -1.30, Win rate : 0.36, Epsilon: 0.01\n","valid latest successed model\n","Valid n:1000, Median progress: 9.00, Median reward: 1.10, Win rate : 0.107\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.096\n","Valid n:1000, Median progress: 9.00, Median reward: 1.00, Win rate : 0.085\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.098\n","Valid n:1000, Median progress: 8.00, Median reward: 0.90, Win rate : 0.078\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.105\n","Valid n:1000, Median progress: 9.00, Median reward: 0.90, Win rate : 0.085\n","Valid n:1000, Median progress: 9.00, Median reward: 1.10, Win rate : 0.113\n","Valid n:1000, Median progress: 10.00, Median reward: 1.20, Win rate : 0.107\n","Valid n:1000, Median progress: 9.00, Median reward: 1.10, Win rate : 0.104\n","Valid n:1000, Median progress: 9.00, Median reward: 1.20, Win rate : 0.095\n","Episode: [100000/35100], Median progress: 18.00, Median reward: -1.30, Win rate : 0.24, Epsilon: 0.01\n","Episode: [100000/35200], Median progress: 16.00, Median reward: -1.00, Win rate : 0.27, Epsilon: 0.01\n","Episode: [100000/35300], Median progress: 13.50, Median reward: -1.30, Win rate : 0.31, Epsilon: 0.01\n","Episode: [100000/35400], Median progress: 18.00, Median reward: -0.70, Win rate : 0.27, Epsilon: 0.01\n","Episode: [100000/35500], Median progress: 17.00, Median reward: -1.00, Win rate : 0.26, Epsilon: 0.01\n","Episode: [100000/35600], Median progress: 13.50, Median reward: -0.70, Win rate : 0.29, Epsilon: 0.01\n","Episode: [100000/35700], Median progress: 12.50, Median reward: -0.55, Win rate : 0.26, Epsilon: 0.01\n","Episode: [100000/35800], Median progress: 14.50, Median reward: -1.15, Win rate : 0.19, Epsilon: 0.01\n"]}],"source":["trainer = Trainer(env=env,\n","                    agent=agent,\n","                    tester_agent=tester_agent,\n","                    name='scalar',\n","                    train_start=True,\n","                    EPISODES = EPISODES,\n","                    PRINT_INTERVAL = PRINT_INTERVAL,\n","                    TRAIN_RENDER = TRAIN_RENDER,\n","                    TRAIN_TIMESTEP = TRAIN_TIMESTEPS[0],\n","                    VIUSAL_INTERVAL = VIUSAL_INTERVAL,\n","                    VALID_SAMPLE = VALID_SAMPLE,\n","                    VALID_INTERVAL = VALID_INTERVAL)"]},{"cell_type":"markdown","metadata":{"id":"gHpenIN_UZtb"},"source":["# Tester"]},{"cell_type":"markdown","metadata":{"id":"BAip84BF8o7x"},"source":["# 03 Tester"]},{"cell_type":"markdown","metadata":{"id":"7j__5_EoB-ON"},"source":["## def tester env, agent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Tp556eZ8fvw"},"outputs":[],"source":["tester_env = LimitedMinesweeperEnv(map_size=level['easy']['map_size'],\n","                                    n_mines=level['easy']['n_mines'],\n","                                    train=False)\n","\n","tester_agent = Agent(env=tester_env,\n","                        net=net,\n","                        MEM_SIZE=MEM_SIZE,\n","                        MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                        BATCH_SIZE=BATCH_SIZE,\n","                        LEARNING_RATE=LEARNING_RATE,\n","                        LEARN_DECAY=LEARN_DECAY,\n","                        LEARN_MIN=LEARN_MIN,\n","                        DISCOUNT=DISCOUNT,\n","                        EPSILON=EPSILON,\n","                        EPSILON_DECAY=EPSILON_DECAY,\n","                        EPSILON_MIN=EPSILON_MIN,\n","                        UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jd2xx1j_aQm"},"outputs":[],"source":["with open(\"/content/drive/MyDrive/Minesweeper [RL]/models/episodeInterval/100000epi_max_train0.75_valid0.462.pkl\",\"rb\") as f:\n","    save_point = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"od7ybX1WBp2S"},"source":["## def tester"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"q0697LCF936i"},"outputs":[],"source":["tester = PerformTester(tester_agent, tester_env, tester_env.n_boards, save_point['best_model_valid'])"]},{"cell_type":"markdown","metadata":{"id":"Eo2PCiPMa8tF"},"source":["## 진 케이스 시각화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x458l626a-V6"},"outputs":[],"source":["target_done = tester.lost_game_done\n","idx_iteration = iter(range(len(target_done)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9PU55rwa-V6"},"outputs":[],"source":["idx = next(idx_iteration)\n","tester.visualize_single_step(target_done.iloc[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AH7YIV0a-V6"},"outputs":[],"source":["target_iter = tester.lost_game_per_epi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gP3ihh5Ia-V6"},"outputs":[],"source":["epi, epi_df = next(target_iter)\n","\n","tester.replay_single_episode(epi_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cv1ijeHoa4NU"},"outputs":[],"source":["tester.lost_more18_percent"]},{"cell_type":"markdown","metadata":{"id":"B-4bzqwFayd4"},"source":["## 승리한 케이스 시각화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSmu4fV1YluE"},"outputs":[],"source":["target_done = tester.won_game_done\n","idx_iteration = iter(range(len(target_done)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEO8VbyBTPjT"},"outputs":[],"source":["idx = next(idx_iteration)\n","tester.visualize_single_step(target_done.iloc[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXQTDANrZMRG"},"outputs":[],"source":["target_iter = tester.won_game_per_epi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tgXWk2XtRTNH"},"outputs":[],"source":["epi, epi_df = next(target_iter)\n","tester.replay_single_episode(epi_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdbY39eZUcMo"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOh8DI8nFOPPnJPR5hWzn2y","collapsed_sections":["78w_wKa0U7RQ","1p29QQ5GAndP","M9gDUMM9WBXa"],"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}