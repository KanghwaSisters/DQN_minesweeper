{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMU332WzWPhpT7nX+lECZT7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rdETq6egdSWb"},"source":["# 00 Init"]},{"cell_type":"markdown","metadata":{"id":"8HOAjQuwL7sN"},"source":["## Mount"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19423,"status":"ok","timestamp":1716014273081,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"},"user_tz":-540},"id":"ui3DIJhjL9gg","outputId":"05e0a082-6a06-4f20-b844-cdf6245bb88c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"78w_wKa0U7RQ"},"source":["## Setting to use py files"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0pxUvG0xL7sP","executionInfo":{"status":"ok","timestamp":1716014273081,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"bMOGX54HPnN4","executionInfo":{"status":"ok","timestamp":1716014273081,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/Minesweeper [RL]')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716014273082,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"},"user_tz":-540},"id":"Irw-aDyCMS39","outputId":"7f54084c-9307-495e-e705-83fc25af33ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Minesweeper [RL]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["# check that os is in right directory\n","os.getcwd()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5303,"status":"ok","timestamp":1716014278382,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"},"user_tz":-540},"id":"Sr1xfdJ6PsFk","outputId":"b9630f04-f4a9-4153-bddf-cd3cc639809c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting codes\n","  Downloading codes-0.1.5-py3-none-any.whl (5.5 kB)\n","Installing collected packages: codes\n","Successfully installed codes-0.1.5\n"]}],"source":["! pip install codes"]},{"cell_type":"markdown","metadata":{"id":"tOZz1bXTVUae"},"source":["## Import py files"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8QtWl0d3Owjd","executionInfo":{"status":"ok","timestamp":1716014291741,"user_tz":-540,"elapsed":13362,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"outputs":[],"source":["# baseline : Env, Agent\n","# from codes.environment.reward5 import *\n","from codes.environment.reward5 import *\n","from codes.agent.vectorDQN import *\n","from codes.agent.vectorDQN import Agent as VectorDQNAgent\n","from codes.agent.scalarDQN import Agent as ScalarDQNAgent\n","from codes.net.basic import *\n","from codes.trainer.validShutDown import *\n","from codes.tester.basic import *\n","# import codes.trainer.trainerWithValidShutDown as Trainer\n"]},{"cell_type":"markdown","metadata":{"id":"pmz1e_BTfYrZ"},"source":["# 01 Info"]},{"cell_type":"markdown","metadata":{"id":"1p29QQ5GAndP"},"source":["## level dictionary"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Vso5fXO-_hH8","executionInfo":{"status":"ok","timestamp":1716014291742,"user_tz":-540,"elapsed":16,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"outputs":[],"source":["level = {'easy' : {'map_size':(9,9), 'n_mines' : 10},\n","         'medium' : {'map_size':(16,16), 'n_mines':40},\n","         'expert' : {'map_size':(16,30), 'n_mines':99}}"]},{"cell_type":"markdown","metadata":{"id":"M9gDUMM9WBXa"},"source":["## HYPER PARAMETERS"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ru8shHIbWDZX","executionInfo":{"status":"ok","timestamp":1716014291742,"user_tz":-540,"elapsed":16,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"outputs":[],"source":["# Environment settings\n","MEM_SIZE = 50000\n","MEM_SIZE_MIN = 1000\n","\n","# Learning settings\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.01\n","LEARN_DECAY = 0.9999975\n","LEARN_MIN = 0.001\n","DISCOUNT = 0.1\n","\n","# Exploration settings\n","EPSILON = 0.95\n","EPSILON_DECAY = 0.99975\n","EPSILON_MIN = 0.01\n","\n","# DQN settings\n","CONV_UNITS = 64\n","UPDATE_TARGET_EVERY = 5"]},{"cell_type":"markdown","source":["## 02 Agents"],"metadata":{"id":"l_TE3KRaj9HG"}},{"cell_type":"markdown","source":["- 로직 비교를 위함이니 역전파 죽이기\n","- 동일한 신경망 사용\n","-"],"metadata":{"id":"XOhkCairk5--"}},{"cell_type":"code","source":["class NewVectorAgent:\n","    def __init__(self, env, net, **kwargs):\n","        self.env = env\n","\n","        # Environment Settings\n","        self.mem_size = kwargs.get(\"MEM_SIZE\")\n","        self.mem_size_min = kwargs.get(\"MEM_SIZE_MIN\")\n","\n","        # Learning Settings\n","        self.batch_size = kwargs.get(\"BATCH_SIZE\")\n","        self.learning_rate = kwargs.get(\"LEARNING_RATE\")\n","        self.learn_decay = kwargs.get(\"LEARN_DECAY\")\n","        self.learn_min = kwargs.get(\"LEARN_MIN\")\n","        self.discount = kwargs.get(\"DISCOUNT\")\n","\n","        # Exploration Settings\n","        self.epsilon = kwargs.get(\"EPSILON\")\n","        self.epsilon_decay = kwargs.get(\"EPSILON_DECAY\")\n","        self.epsilon_min = kwargs.get(\"EPSILON_MIN\")\n","\n","        # loss\n","        self.loss_fn = nn.MSELoss()\n","        self.losses = []\n","\n","        # target net update\n","        self.target_update_counter = 0\n","        self.update_target_baseline = kwargs.get(\"UPDATE_TARGET_EVERY\")\n","\n","        # def model\n","        self.model = copy.deepcopy(net)\n","        self.target_model = copy.deepcopy(net)\n","\n","        self.target_model.load_state_dict(self.model.state_dict())\n","\n","        self.model.to(device)\n","        self.target_model.to(device)\n","\n","        # replay memory\n","        self.replay_memory = deque(maxlen=self.mem_size)\n","\n","    def update_target_model(self):\n","        self.target_model.load_state_dict(self.model.state_dict())\n","\n","    def update_replay_memory(self, transition):\n","        self.replay_memory.append(transition)\n","\n","    def get_action(self, state):\n","        '''\n","        get_action은 하나의 state_img만을 받는다.\n","        '''\n","        if np.random.random() < self.epsilon:\n","            # take random action\n","            action = np.random.choice(range(self.env.total_tiles))\n","\n","        else:\n","            self.model.eval()\n","\n","            with torch.no_grad():\n","                state = torch.tensor(state.reshape(1,1,self.env.nrows,self.env.ncols),\n","                                     dtype=torch.float32).to(device)\n","                total_action = self.model(state).view(-1)\n","                total_action = total_action.cpu()\n","\n","                self.total_action = total_action\n","\n","                action = torch.argmax(total_action).item()\n","\n","        return action\n","\n","    def train(self, done, batch):\n","        if len(self.replay_memory) < self.mem_size_min:\n","            return\n","\n","        # optimizer\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-4)\n","\n","        # 리플레이 메모리에서 배치 사이즈만큼 데이터를 꺼낸다.\n","        # batch[i] = (current_state, action, reward, new_current_state, done)\n","        # batch = random.sample(self.replay_memory, self.batch_size)\n","\n","        # 배치 안에 저장되어 있는 정보 꺼내기\n","        current_states, actions, rewards, next_states, epi_dones = zip(*batch)\n","\n","        current_states =  torch.tensor(np.array(current_states), dtype=torch.float32).reshape(-1,1,self.env.nrows,self.env.ncols).to(device)\n","        next_states = torch.tensor(np.array(next_states), dtype=torch.float32).reshape(-1,1,self.env.nrows,self.env.ncols).to(device)\n","\n","        actions = torch.tensor(np.array(actions), dtype=torch.int).to(device)\n","        rewards = torch.tensor(np.array(rewards), dtype=torch.float).reshape(-1,1).to(device)\n","        epi_dones = torch.tensor(np.array(epi_dones), dtype=torch.float).reshape(-1,1).to(device)\n","\n","        self.model.train()\n","        self.target_model.eval()\n","\n","        current_q_values = self.model(current_states)\n","\n","        with torch.no_grad():\n","            next_q_values = self.target_model(next_states)\n","\n","        target_value = rewards + (1 - epi_dones) * self.discount * torch.max(next_q_values, dim=1)[0].reshape(-1,1)\n","        target_value = target_value.flatten()\n","\n","        target_q_values = copy.deepcopy(current_q_values.detach())\n","        target_q_values[range(BATCH_SIZE), actions] = target_value\n","\n","        self.action = actions\n","        self.dones = epi_dones\n","        self.target_q_values = target_q_values\n","        self.pred_q_values = current_q_values\n","\n","        cost = self.loss_fn(current_q_values, target_q_values)\n","\n","        running_loss = cost.item()\n","\n","        self.current_loss = running_loss\n","\n","        self.losses.append(round(running_loss,6))\n","\n","        # self.optimizer.zero_grad()\n","        # cost.backward()\n","        # self.optimizer.step()\n","\n","        if done:\n","            self.target_update_counter += 1\n","\n","        if self.target_update_counter == self.update_target_baseline:\n","            self.update_target_model()\n","            self.target_update_counter = 0\n","\n","        # decay learning rate\n","        self.learning_rate = max(self.learn_min, self.learning_rate*self.learn_decay)\n","\n","        # decay epsilon\n","        self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)"],"metadata":{"id":"BrKSsnzrj_SY","executionInfo":{"status":"ok","timestamp":1716016193625,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["class ScalarAgent(ScalarDQNAgent):\n","    def __init__(self, env, net, **kwargs):\n","        super().__init__(env, net, **kwargs)\n","\n","    def train(self, done, batch):\n","        if len(self.replay_memory) < self.mem_size_min:\n","            return\n","\n","        # optimizer\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-4)\n","\n","        self.model.train()\n","        self.target_model.eval()\n","\n","        # 리플레이 메모리에서 배치 사이즈만큼 데이터를 꺼낸다.\n","        # batch[i] = (current_state, action, reward, next_state, done)\n","        # batch = random.sample(self.replay_memory, self.batch_size)\n","\n","        # 배치 안에 저장되어 있는 정보 꺼내기\n","        current_states, batched_actions, batched_rewards, next_states, batched_dones = zip(*batch)\n","\n","        # state 정의\n","        current_states = torch.tensor(np.array(current_states), dtype=torch.float32, device=device).reshape(-1,1,self.env.nrows,self.env.ncols)\n","        next_states = torch.tensor(np.array(next_states), dtype=torch.float32, device=device).reshape(-1,1,self.env.nrows,self.env.ncols)\n","\n","        action_batch = torch.tensor(batched_actions, device=device).reshape(-1,1) # reshape 안해주면 index로써 사용할 수 없다.\n","        reward_batch = torch.tensor(batched_rewards, device=device).reshape(-1,1)\n","        done_batch = torch.tensor(batched_dones, dtype=torch.float32, device=device).reshape(-1,1) # bool -> 0/1\n","\n","        # Q(s,a) 값을 예측값으로 사용 - (batch, action_space.n)\n","        pred_q_values = self.model(current_states).gather(1, action_batch) # action idx의 데이터만 꺼냄\n","\n","        # target 값 계산 : reward + gamma * Q(s',a')\n","        with torch.no_grad():\n","            next_q_values = self.target_model(next_states).max(1).values.reshape(-1,1)\n","            target_q_values = reward_batch + (torch.ones(next_q_values.shape, device=device) - done_batch) * self.discount * next_q_values\n","\n","        self.target_q_values = target_q_values\n","        self.pred_q_values = pred_q_values\n","\n","        loss = self.loss_fn(pred_q_values, target_q_values)\n","\n","        running_loss = loss.item()\n","\n","        self.current_loss = running_loss\n","\n","        self.losses.append(round(running_loss,6))\n","\n","        # self.optimizer.zero_grad()\n","        # loss.backward()\n","        # self.optimizer.step()\n","\n","        if done:\n","            self.target_update_counter += 1\n","\n","        if self.target_update_counter == self.update_target_baseline:\n","            self.update_target_model()\n","            self.target_update_counter = 0\n","\n","        # decay learning rate\n","        self.learning_rate = max(self.learn_min, self.learning_rate*self.learn_decay)\n","\n","        # decay epsilon\n","        self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)"],"metadata":{"id":"hJgJoJRpkLmn","executionInfo":{"status":"ok","timestamp":1716015410290,"user_tz":-540,"elapsed":473,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["class VectorAgent(VectorDQNAgent):\n","    def __init__(self, env, net, **kwargs):\n","        super().__init__(env, net, **kwargs)\n","\n","    def train(self, done, batch):\n","        if len(self.replay_memory) < self.mem_size_min:\n","            return\n","\n","        # optimizer\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-4)\n","\n","        # 리플레이 메모리에서 배치 사이즈만큼 데이터를 꺼낸다.\n","        # batch[i] = (current_state, action, reward, new_current_state, done)\n","        # batch = random.sample(self.replay_memory, self.batch_size)\n","\n","        # 배치 안에 저장되어 있는 정보 꺼내기\n","        current_states, _, _, next_states, _ = zip(*batch)\n","\n","\n","        current_states =  torch.tensor(np.array(current_states), dtype=torch.float32).reshape(-1,1,self.env.nrows,self.env.ncols).to(device)\n","        next_states = torch.tensor(np.array(next_states), dtype=torch.float32).reshape(-1,1,self.env.nrows,self.env.ncols).to(device)\n","\n","        self.model.eval()\n","        self.target_model.eval()\n","\n","        with torch.no_grad():\n","            current_q_values = self.model(current_states).reshape(-1,self.env.total_tiles).cpu().detach().tolist()\n","            next_q_values = self.target_model(next_states).cpu().detach().numpy()\n","\n","        #  current_q_values를 target value가 되도록 업데이트하는 코드\n","        for index, (_, action, reward, _, epi_done) in enumerate(batch):\n","            if not epi_done:\n","                max_future_q = np.max(next_q_values[index])\n","                new_q = reward + self.discount * max_future_q\n","            else:\n","                new_q = reward\n","\n","            current_q_values[index][action] = new_q\n","\n","        # train model\n","        self.model.train()\n","\n","        x = current_states.to(device)\n","        y = torch.tensor(np.array(current_q_values), dtype=torch.float32).to(device)\n","\n","        y_est = self.model(x)\n","\n","        self.target_q_values = y\n","        self.pred_q_values = y_est\n","\n","        cost = self.loss_fn(y_est, y)\n","\n","        running_loss = cost.item()\n","\n","        self.current_loss = running_loss\n","\n","        self.losses.append(round(running_loss,6))\n","\n","        # self.optimizer.zero_grad()\n","        # cost.backward()\n","        # self.optimizer.step()\n","\n","        if done:\n","            self.target_update_counter += 1\n","\n","        if self.target_update_counter == self.update_target_baseline:\n","            self.update_target_model()\n","            self.target_update_counter = 0\n","\n","        # decay learning rate\n","        self.learning_rate = max(self.learn_min, self.learning_rate*self.learn_decay)\n","\n","        # decay epsilon\n","        self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)"],"metadata":{"id":"QtPH-2SglijJ","executionInfo":{"status":"ok","timestamp":1716015410763,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TSbDwBaZgg46"},"source":["# 02 Train, Valid"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"9YIE1PWMO1Sm","executionInfo":{"status":"ok","timestamp":1716015413300,"user_tz":-540,"elapsed":471,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"outputs":[],"source":["env = MinesweeperEnv(map_size=level['easy']['map_size'],\n","                     n_mines=level['easy']['n_mines'])\n","\n","net = Net(input_dims=env.state.shape,\n","          n_actions=env.total_tiles,\n","          conv_units=CONV_UNITS)"]},{"cell_type":"code","source":["new_vector_agent = NewVectorAgent(env=env,\n","                                    net=net,\n","                                    MEM_SIZE=MEM_SIZE,\n","                                    MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                                    BATCH_SIZE=BATCH_SIZE,\n","                                    LEARNING_RATE=LEARNING_RATE,\n","                                    LEARN_DECAY=LEARN_DECAY,\n","                                    LEARN_MIN=LEARN_MIN,\n","                                    DISCOUNT=DISCOUNT,\n","                                    EPSILON=EPSILON,\n","                                    EPSILON_DECAY=EPSILON_DECAY,\n","                                    EPSILON_MIN=EPSILON_MIN,\n","                                    UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)\n","\n","vector_agent = VectorAgent(env=env,\n","                                net=net,\n","                                MEM_SIZE=MEM_SIZE,\n","                                MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                                BATCH_SIZE=BATCH_SIZE,\n","                                LEARNING_RATE=LEARNING_RATE,\n","                                LEARN_DECAY=LEARN_DECAY,\n","                                LEARN_MIN=LEARN_MIN,\n","                                DISCOUNT=DISCOUNT,\n","                                EPSILON=EPSILON,\n","                                EPSILON_DECAY=EPSILON_DECAY,\n","                                EPSILON_MIN=EPSILON_MIN,\n","                                UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)\n","\n","scalar_agent = ScalarAgent(env=env,\n","                                net=net,\n","                                MEM_SIZE=MEM_SIZE,\n","                                MEM_SIZE_MIN=MEM_SIZE_MIN,\n","                                BATCH_SIZE=BATCH_SIZE,\n","                                LEARNING_RATE=LEARNING_RATE,\n","                                LEARN_DECAY=LEARN_DECAY,\n","                                LEARN_MIN=LEARN_MIN,\n","                                DISCOUNT=DISCOUNT,\n","                                EPSILON=EPSILON,\n","                                EPSILON_DECAY=EPSILON_DECAY,\n","                                EPSILON_MIN=EPSILON_MIN,\n","                                UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY)"],"metadata":{"id":"rczP9UiGnIrc","executionInfo":{"status":"ok","timestamp":1716016200505,"user_tz":-540,"elapsed":542,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}}},"execution_count":76,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7L5dNbnpiYjH"},"source":["## TRAIN_PARAMETERS"]},{"cell_type":"code","source":["EPISODES = 300\n","\n","PRINT_INTERVAL = 100\n","\n","TRAIN_RENDER = False\n","reward_list = []\n","mean_rewards = []"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716016201936,"user_tz":-540,"elapsed":327,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"id":"YAuB74OnNhcE"},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","\n","for episode in range(EPISODES):\n","    env.reset()\n","    done = False\n","\n","    while not done:\n","        current_state = env.state\n","\n","        action = new_vector_agent.get_action(current_state)\n","        next_state, reward, done = env.step(action)\n","\n","        new_vector_agent.update_replay_memory((current_state, action, reward, next_state, done))\n","        vector_agent.update_replay_memory((current_state, action, reward, next_state, done))\n","        scalar_agent.update_replay_memory((current_state, action, reward, next_state, done))\n","\n","        if len(new_vector_agent.replay_memory) >= new_vector_agent.batch_size:\n","            batch = random.sample(new_vector_agent.replay_memory, new_vector_agent.batch_size)\n","\n","            new_vector_agent.train(done, batch)\n","            vector_agent.train(done, batch)\n","            scalar_agent.train(done, batch)\n","\n","        current_state = next_state\n","\n","        if TRAIN_RENDER:\n","            env.render()\n","\n","    # reward_list.append(reward)\n","\n","    # if (episode+1) % PRINT_INTERVAL == 0:\n","    #     mean_reward = np.mean(reward_list[-PRINT_INTERVAL:])\n","    #     mean_rewards.append(mean_reward)\n","    #     print(f\"Episode: [{EPISODES}/{episode+1}] | Mean reward: {mean_reward:.2f} | Epsilon: {agent.epsilon:3f}\")\n","\n","print(round(time.time() - start,2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716016226779,"user_tz":-540,"elapsed":24118,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"610f2eae-ef31-4161-a437-a34213d23937","id":"YyUI7Yw8NhcE"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["23.88\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame({'action' : new_vector_agent.action.cpu().detach().numpy(),\n","                    'done' : list(new_vector_agent.dones.cpu().detach().numpy()),\n","                    'new_vector_agent_pred' : list(new_vector_agent.pred_q_values.cpu().detach().numpy()),\n","                    'new_vector_agent_trg' : list(new_vector_agent.target_q_values.cpu().detach().numpy()),\n","                    'new_vector_agent_loss' : new_vector_agent.current_loss,\n","\n","                    'vector_agent_pred' : list(vector_agent.pred_q_values.cpu().detach().numpy()),\n","                    'vector_agent_trg' : list(vector_agent.target_q_values.cpu().detach().numpy()),\n","                    'vector_agent_loss' : vector_agent.current_loss,\n","\n","                    'scalar_agent_pred' : list(scalar_agent.pred_q_values.cpu().detach().numpy()),\n","                    'scalar_agent_trg' : list(scalar_agent.target_q_values.cpu().detach().numpy()),\n","                    'scalar_agent_loss' : scalar_agent.current_loss\n","                    })\n","\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"YUvNz2kXpVSH","executionInfo":{"status":"ok","timestamp":1716016226779,"user_tz":-540,"elapsed":6,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"0d0cfa7f-277b-4b0f-c53c-00b1eeb55f2a"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   action   done                              new_vector_agent_pred  \\\n","0      32  [0.0]  [-0.012740556, 0.0032430163, 0.0045295134, -0....   \n","1      12  [1.0]  [-0.011348023, 0.00420004, 0.0035170526, 0.000...   \n","2      48  [0.0]  [-0.011057192, 0.003720354, 0.0061896453, 0.00...   \n","3      31  [0.0]  [-0.012024426, 0.003561283, 0.0042827404, 0.00...   \n","4      58  [0.0]  [-0.012048509, 0.0038842675, 0.0047334423, -0....   \n","\n","                                new_vector_agent_trg  new_vector_agent_loss  \\\n","0  [-0.012740556, 0.0032430163, 0.0045295134, -0....               0.002002   \n","1  [-0.011348023, 0.00420004, 0.0035170526, 0.000...               0.002002   \n","2  [-0.011057192, 0.003720354, 0.0061896453, 0.00...               0.002002   \n","3  [-0.012024426, 0.003561283, 0.0042827404, 0.00...               0.002002   \n","4  [-0.012048509, 0.0038842675, 0.0047334423, -0....               0.002002   \n","\n","                                   vector_agent_pred  \\\n","0  [-0.012740556, 0.0032430163, 0.0045295134, -0....   \n","1  [-0.011348023, 0.00420004, 0.0035170526, 0.000...   \n","2  [-0.011057192, 0.003720354, 0.0061896453, 0.00...   \n","3  [-0.012024426, 0.003561283, 0.0042827404, 0.00...   \n","4  [-0.012048509, 0.0038842675, 0.0047334423, -0....   \n","\n","                                    vector_agent_trg  vector_agent_loss  \\\n","0  [-0.012740556, 0.0032430163, 0.0045295134, -0....           0.002002   \n","1  [-0.011348023, 0.00420004, 0.0035170526, 0.000...           0.002002   \n","2  [-0.011057192, 0.003720354, 0.0061896453, 0.00...           0.002002   \n","3  [-0.012024426, 0.003561283, 0.0042827404, 0.00...           0.002002   \n","4  [-0.012048509, 0.0038842675, 0.0047334423, -0....           0.002002   \n","\n","  scalar_agent_pred scalar_agent_trg  scalar_agent_loss  \n","0   [-0.0068920436]     [0.30115378]           0.162187  \n","1     [0.008917493]           [-1.0]           0.162187  \n","2    [-0.010494717]     [0.30094016]           0.162187  \n","3     [0.010939166]     [-0.2989061]           0.162187  \n","4   [-0.0056102937]     [-0.2988317]           0.162187  "],"text/html":["\n","  <div id=\"df-3f495e7d-fa03-4983-83de-d89065028da0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>action</th>\n","      <th>done</th>\n","      <th>new_vector_agent_pred</th>\n","      <th>new_vector_agent_trg</th>\n","      <th>new_vector_agent_loss</th>\n","      <th>vector_agent_pred</th>\n","      <th>vector_agent_trg</th>\n","      <th>vector_agent_loss</th>\n","      <th>scalar_agent_pred</th>\n","      <th>scalar_agent_trg</th>\n","      <th>scalar_agent_loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>32</td>\n","      <td>[0.0]</td>\n","      <td>[-0.012740556, 0.0032430163, 0.0045295134, -0....</td>\n","      <td>[-0.012740556, 0.0032430163, 0.0045295134, -0....</td>\n","      <td>0.002002</td>\n","      <td>[-0.012740556, 0.0032430163, 0.0045295134, -0....</td>\n","      <td>[-0.012740556, 0.0032430163, 0.0045295134, -0....</td>\n","      <td>0.002002</td>\n","      <td>[-0.0068920436]</td>\n","      <td>[0.30115378]</td>\n","      <td>0.162187</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12</td>\n","      <td>[1.0]</td>\n","      <td>[-0.011348023, 0.00420004, 0.0035170526, 0.000...</td>\n","      <td>[-0.011348023, 0.00420004, 0.0035170526, 0.000...</td>\n","      <td>0.002002</td>\n","      <td>[-0.011348023, 0.00420004, 0.0035170526, 0.000...</td>\n","      <td>[-0.011348023, 0.00420004, 0.0035170526, 0.000...</td>\n","      <td>0.002002</td>\n","      <td>[0.008917493]</td>\n","      <td>[-1.0]</td>\n","      <td>0.162187</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>48</td>\n","      <td>[0.0]</td>\n","      <td>[-0.011057192, 0.003720354, 0.0061896453, 0.00...</td>\n","      <td>[-0.011057192, 0.003720354, 0.0061896453, 0.00...</td>\n","      <td>0.002002</td>\n","      <td>[-0.011057192, 0.003720354, 0.0061896453, 0.00...</td>\n","      <td>[-0.011057192, 0.003720354, 0.0061896453, 0.00...</td>\n","      <td>0.002002</td>\n","      <td>[-0.010494717]</td>\n","      <td>[0.30094016]</td>\n","      <td>0.162187</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>31</td>\n","      <td>[0.0]</td>\n","      <td>[-0.012024426, 0.003561283, 0.0042827404, 0.00...</td>\n","      <td>[-0.012024426, 0.003561283, 0.0042827404, 0.00...</td>\n","      <td>0.002002</td>\n","      <td>[-0.012024426, 0.003561283, 0.0042827404, 0.00...</td>\n","      <td>[-0.012024426, 0.003561283, 0.0042827404, 0.00...</td>\n","      <td>0.002002</td>\n","      <td>[0.010939166]</td>\n","      <td>[-0.2989061]</td>\n","      <td>0.162187</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58</td>\n","      <td>[0.0]</td>\n","      <td>[-0.012048509, 0.0038842675, 0.0047334423, -0....</td>\n","      <td>[-0.012048509, 0.0038842675, 0.0047334423, -0....</td>\n","      <td>0.002002</td>\n","      <td>[-0.012048509, 0.0038842675, 0.0047334423, -0....</td>\n","      <td>[-0.012048509, 0.0038842675, 0.0047334423, -0....</td>\n","      <td>0.002002</td>\n","      <td>[-0.0056102937]</td>\n","      <td>[-0.2988317]</td>\n","      <td>0.162187</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f495e7d-fa03-4983-83de-d89065028da0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3f495e7d-fa03-4983-83de-d89065028da0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3f495e7d-fa03-4983-83de-d89065028da0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0e070e4d-68ba-46c9-9de6-08347082e8d3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e070e4d-68ba-46c9-9de6-08347082e8d3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0e070e4d-68ba-46c9-9de6-08347082e8d3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 64,\n  \"fields\": [\n    {\n      \"column\": \"action\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          35,\n          78,\n          58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"done\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_vector_agent_pred\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_vector_agent_trg\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_vector_agent_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.002002306515350938,\n        \"max\": 0.002002306515350938,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.002002306515350938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector_agent_pred\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector_agent_trg\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector_agent_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.002002306515350938,\n        \"max\": 0.002002306515350938,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.002002306515350938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scalar_agent_pred\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scalar_agent_trg\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scalar_agent_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.16218683123588562,\n        \"max\": 0.16218683123588562,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.16218683123588562\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["df['new_vector_agent_pred'][2][5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUQNsBxquEzU","executionInfo":{"status":"ok","timestamp":1715969013125,"user_tz":-540,"elapsed":431,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"f04f9476-d154-4454-f971-63a979a3d4fc"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.0061555402"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["idx = 1\n","df['new_vector_agent_trg'][idx] == df['new_vector_agent_pred'][idx]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spcNNefYrSKm","executionInfo":{"status":"ok","timestamp":1716016270636,"user_tz":-540,"elapsed":527,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"efabc87e-130a-42c9-b531-b8a826a03681"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True, False,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True])"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["idx = 1\n","df['vector_agent_trg'][idx] == df['vector_agent_pred'][idx]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20rcnNjpraui","executionInfo":{"status":"ok","timestamp":1716016282642,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"f236b102-df3f-45bc-ab92-09346e9cc160"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True, False,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True])"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["\n","df['new_vector_agent_trg'][idx] == df['vector_agent_trg'][idx]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxJxITnFrDMk","executionInfo":{"status":"ok","timestamp":1716016306389,"user_tz":-540,"elapsed":384,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"33e8d4ff-5396-4458-d3b4-98075fb72435"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True])"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["print(df['new_vector_agent_trg'][idx][df['action'][idx]])\n","print(df['vector_agent_trg'][idx][df['action'][idx]])\n","df['scalar_agent_trg'][idx].tolist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdLFs3NEriJd","executionInfo":{"status":"ok","timestamp":1716016340062,"user_tz":-540,"elapsed":338,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"96a981d2-3ed9-4d47-b602-3d4c65c5fdba"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["-1.0\n","-1.0\n"]},{"output_type":"execute_result","data":{"text/plain":["[-1.0]"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["print(df['new_vector_agent_pred'][idx][df['action'][idx]])\n","print(df['vector_agent_pred'][idx][df['action'][idx]])\n","df['scalar_agent_pred'][idx].tolist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6odPfFc7fgGd","executionInfo":{"status":"ok","timestamp":1716016342649,"user_tz":-540,"elapsed":288,"user":{"displayName":"Jimin Lee","userId":"01372747766781604817"}},"outputId":"aa127272-9c97-4b53-993d-a4799e7d2018"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["0.008917493\n","0.008917493\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.008917492814362049]"]},"metadata":{},"execution_count":84}]},{"cell_type":"markdown","source":["[-0.2987838]"],"metadata":{"id":"1w5YdFC4sJbM"}}]}